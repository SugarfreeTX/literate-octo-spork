{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913f9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "quest_1 = pd.read_excel(r'C:\\Users\\e745092\\OneDrive - Baylor Scott & White Health\\Desktop\\SHRADDHA\\FW PBI Concepts\\BUMC_september2025_report_v2_01192026.xlsx') # , sheet_name='Sheet1'\n",
    "quest_2 = pd.read_excel(r'C:\\Users\\e745092\\OneDrive - Baylor Scott & White Health\\Desktop\\SHRADDHA\\FW PBI Concepts\\quest_score_output.xlsx') # , sheet_name='Sheet1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e88f8a",
   "metadata": {},
   "source": [
    "## **1. Structure Comparison**\n",
    "\n",
    "This section compares the basic structural elements of both dataframes:\n",
    "- **Shape**: Number of rows and columns\n",
    "- **Column names**: Exact column name matching\n",
    "- **Data types**: Data type consistency across columns\n",
    "- **Index**: Index structure and alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eabdb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SHAPE COMPARISON\n",
      "============================================================\n",
      "Quest 1 shape: (46, 15)\n",
      "Quest 2 shape: (45, 15)\n",
      "Shape match: False\n",
      "\n",
      "============================================================\n",
      "COLUMN COMPARISON\n",
      "============================================================\n",
      "Quest 1 columns: ['Subject_id', 'TIOB_site', 'TIOB Visit Month', 'Visit Type', 'Visit Coordination', 'Blood (5 tubes)', 'Urine (2 cups)', 'Stool', 'Questionnaire', 'Blood Collection-to-processing', 'Urine Collection-to-processing', 'Blood quality', 'Data Entry in Verily', 'Total_quest_score', 'Tier']\n",
      "Quest 2 columns: ['subject_id', 'TIOB_site', 'TIOB Visit Month', 'Visit Type', 'Visit Coordination', 'Blood (5 tubes)', 'Urine (2 cups)', 'Stool', 'Questionnaire', 'Blood Collection-to-processing', 'Urine Collection-to-processing', 'Blood quality', 'Data Entry in Verily', 'Total_quest_score', 'Tier']\n",
      "Columns match: False\n",
      "Columns in Quest 1 but not Quest 2: {'Subject_id'}\n",
      "Columns in Quest 2 but not Quest 1: {'subject_id'}\n",
      "\n",
      "============================================================\n",
      "DATA TYPES COMPARISON\n",
      "============================================================\n",
      "                                 Quest_1_dtype   Quest_2_dtype\n",
      "Blood (5 tubes)                        float64         float64\n",
      "Blood Collection-to-processing         float64         float64\n",
      "Blood quality                          float64         float64\n",
      "Data Entry in Verily                     int64           int64\n",
      "Questionnaire                          float64           int64\n",
      "Stool                                  float64         float64\n",
      "Subject_id                              object             NaN\n",
      "TIOB Visit Month                datetime64[ns]  datetime64[ns]\n",
      "TIOB_site                               object          object\n",
      "Tier                                     int64           int64\n",
      "Total_quest_score                      float64         float64\n",
      "Urine (2 cups)                         float64         float64\n",
      "Urine Collection-to-processing         float64         float64\n",
      "Visit Coordination                       int64           int64\n",
      "Visit Type                              object          object\n",
      "subject_id                                 NaN          object\n",
      "\n",
      "============================================================\n",
      "INDEX COMPARISON\n",
      "============================================================\n",
      "Quest 1 index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "Quest 2 index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "Index ranges match: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Basic shape comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"SHAPE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Quest 1 shape: {quest_1.shape}\")\n",
    "print(f\"Quest 2 shape: {quest_2.shape}\")\n",
    "print(f\"Shape match: {quest_1.shape == quest_2.shape}\")\n",
    "print()\n",
    "\n",
    "# Column comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"COLUMN COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Quest 1 columns: {list(quest_1.columns)}\")\n",
    "print(f\"Quest 2 columns: {list(quest_2.columns)}\")\n",
    "print(f\"Columns match: {list(quest_1.columns) == list(quest_2.columns)}\")\n",
    "\n",
    "# Check for missing columns\n",
    "missing_in_quest2 = set(quest_1.columns) - set(quest_2.columns)\n",
    "missing_in_quest1 = set(quest_2.columns) - set(quest_1.columns)\n",
    "\n",
    "if missing_in_quest2:\n",
    "    print(f\"Columns in Quest 1 but not Quest 2: {missing_in_quest2}\")\n",
    "if missing_in_quest1:\n",
    "    print(f\"Columns in Quest 2 but not Quest 1: {missing_in_quest1}\")\n",
    "print()\n",
    "\n",
    "# Data types comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA TYPES COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "dtypes_comparison = pd.DataFrame({\n",
    "    'Quest_1_dtype': quest_1.dtypes,\n",
    "    'Quest_2_dtype': quest_2.dtypes\n",
    "})\n",
    "print(dtypes_comparison)\n",
    "\n",
    "# Check for data type mismatches\n",
    "if list(quest_1.columns) == list(quest_2.columns):\n",
    "    dtype_mismatches = []\n",
    "    for col in quest_1.columns:\n",
    "        if col in quest_2.columns and quest_1[col].dtype != quest_2[col].dtype:\n",
    "            dtype_mismatches.append(col)\n",
    "    \n",
    "    if dtype_mismatches:\n",
    "        print(f\"\\nData type mismatches in columns: {dtype_mismatches}\")\n",
    "    else:\n",
    "        print(\"\\nAll data types match!\")\n",
    "print()\n",
    "\n",
    "# Index comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"INDEX COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Quest 1 index type: {type(quest_1.index)}\")\n",
    "print(f\"Quest 2 index type: {type(quest_2.index)}\")\n",
    "print(f\"Index ranges match: {quest_1.index.equals(quest_2.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a89a2",
   "metadata": {},
   "source": [
    "## **2. Basic Data Profiling**\n",
    "\n",
    "This section compares data quality and distribution patterns between both dataframes:\n",
    "- **Missing values**: Count and compare null/missing values per column \n",
    "- **Unique values**: Compare unique value counts for categorical columns \n",
    "- **Data ranges**: Compare min/max values for numerical columns \n",
    "- **Summary statistics**: Compare means, medians, and standard deviations\n",
    "- **Duplicate records**: Check for and compare duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f243078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MISSING VALUES COMPARISON\n",
      "============================================================\n",
      "                                Quest_1_missing  Quest_2_missing  Difference  \\\n",
      "Blood (5 tubes)                             0.0              0.0         0.0   \n",
      "Blood Collection-to-processing              0.0              0.0         0.0   \n",
      "Blood quality                               0.0              0.0         0.0   \n",
      "Data Entry in Verily                        0.0              0.0         0.0   \n",
      "Questionnaire                               1.0              0.0         1.0   \n",
      "Stool                                       0.0              0.0         0.0   \n",
      "Subject_id                                  0.0              NaN         NaN   \n",
      "TIOB Visit Month                            1.0              0.0         1.0   \n",
      "TIOB_site                                   1.0              0.0         1.0   \n",
      "Tier                                        0.0              0.0         0.0   \n",
      "Total_quest_score                           0.0              0.0         0.0   \n",
      "Urine (2 cups)                              0.0              0.0         0.0   \n",
      "Urine Collection-to-processing              0.0              0.0         0.0   \n",
      "Visit Coordination                          0.0              0.0         0.0   \n",
      "Visit Type                                  0.0              0.0         0.0   \n",
      "subject_id                                  NaN              0.0         NaN   \n",
      "\n",
      "                                Quest_1_%  Quest_2_%  \n",
      "Blood (5 tubes)                      0.00        0.0  \n",
      "Blood Collection-to-processing       0.00        0.0  \n",
      "Blood quality                        0.00        0.0  \n",
      "Data Entry in Verily                 0.00        0.0  \n",
      "Questionnaire                        2.17        0.0  \n",
      "Stool                                0.00        0.0  \n",
      "Subject_id                           0.00        NaN  \n",
      "TIOB Visit Month                     2.17        0.0  \n",
      "TIOB_site                            2.17        0.0  \n",
      "Tier                                 0.00        0.0  \n",
      "Total_quest_score                    0.00        0.0  \n",
      "Urine (2 cups)                       0.00        0.0  \n",
      "Urine Collection-to-processing       0.00        0.0  \n",
      "Visit Coordination                   0.00        0.0  \n",
      "Visit Type                           0.00        0.0  \n",
      "subject_id                            NaN        0.0  \n",
      "\n",
      "Total missing values - Quest 1: 3\n",
      "Total missing values - Quest 2: 0\n",
      "\n",
      "Columns with differing missing value counts (5):\n",
      "                  Quest_1_missing  Quest_2_missing  Difference  Quest_1_%  \\\n",
      "Questionnaire                 1.0              0.0         1.0       2.17   \n",
      "Subject_id                    0.0              NaN         NaN       0.00   \n",
      "TIOB Visit Month              1.0              0.0         1.0       2.17   \n",
      "TIOB_site                     1.0              0.0         1.0       2.17   \n",
      "subject_id                    NaN              0.0         NaN        NaN   \n",
      "\n",
      "                  Quest_2_%  \n",
      "Questionnaire           0.0  \n",
      "Subject_id              NaN  \n",
      "TIOB Visit Month        0.0  \n",
      "TIOB_site               0.0  \n",
      "subject_id              0.0  \n",
      "\n",
      "============================================================\n",
      "UNIQUE VALUES COMPARISON\n",
      "============================================================\n",
      "                                Quest_1_unique  Quest_2_unique  Difference  \\\n",
      "Blood (5 tubes)                            9.0             8.0         1.0   \n",
      "Blood Collection-to-processing             3.0             3.0         0.0   \n",
      "Blood quality                              3.0             3.0         0.0   \n",
      "Data Entry in Verily                       2.0             2.0         0.0   \n",
      "Questionnaire                              2.0             2.0         0.0   \n",
      "Stool                                      2.0             2.0         0.0   \n",
      "Subject_id                                43.0             NaN         NaN   \n",
      "TIOB Visit Month                          19.0            19.0         0.0   \n",
      "TIOB_site                                  1.0             1.0         0.0   \n",
      "Tier                                       3.0             3.0         0.0   \n",
      "Total_quest_score                         16.0            16.0         0.0   \n",
      "Urine (2 cups)                             3.0             3.0         0.0   \n",
      "Urine Collection-to-processing             3.0             3.0         0.0   \n",
      "Visit Coordination                         2.0             1.0         1.0   \n",
      "Visit Type                                10.0            10.0         0.0   \n",
      "subject_id                                 NaN            42.0         NaN   \n",
      "\n",
      "                                Quest_1_%_unique  Quest_2_%_unique  \n",
      "Blood (5 tubes)                            19.57             17.78  \n",
      "Blood Collection-to-processing              6.52              6.67  \n",
      "Blood quality                               6.52              6.67  \n",
      "Data Entry in Verily                        4.35              4.44  \n",
      "Questionnaire                               4.35              4.44  \n",
      "Stool                                       4.35              4.44  \n",
      "Subject_id                                 93.48               NaN  \n",
      "TIOB Visit Month                           41.30             42.22  \n",
      "TIOB_site                                   2.17              2.22  \n",
      "Tier                                        6.52              6.67  \n",
      "Total_quest_score                          34.78             35.56  \n",
      "Urine (2 cups)                              6.52              6.67  \n",
      "Urine Collection-to-processing              6.52              6.67  \n",
      "Visit Coordination                          4.35              2.22  \n",
      "Visit Type                                 21.74             22.22  \n",
      "subject_id                                   NaN             93.33  \n",
      "\n",
      "Columns with differing unique value counts (4):\n",
      "                    Quest_1_unique  Quest_2_unique  Difference  \\\n",
      "Blood (5 tubes)                9.0             8.0         1.0   \n",
      "Subject_id                    43.0             NaN         NaN   \n",
      "Visit Coordination             2.0             1.0         1.0   \n",
      "subject_id                     NaN            42.0         NaN   \n",
      "\n",
      "                    Quest_1_%_unique  Quest_2_%_unique  \n",
      "Blood (5 tubes)                19.57             17.78  \n",
      "Subject_id                     93.48               NaN  \n",
      "Visit Coordination              4.35              2.22  \n",
      "subject_id                       NaN             93.33  \n",
      "\n",
      "Potential categorical columns (< 5.0% unique values):\n",
      "Quest_1: ['Visit Coordination', 'Stool', 'Questionnaire', 'Data Entry in Verily']\n",
      "Quest_2: ['Stool', 'Questionnaire', 'Data Entry in Verily']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing values comparison\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "missing_quest1 = quest_1.isnull().sum()\n",
    "missing_quest2 = quest_2.isnull().sum()\n",
    "missing_comparison = pd.DataFrame({\n",
    "    'Quest_1_missing': missing_quest1,\n",
    "    'Quest_2_missing': missing_quest2,\n",
    "    'Difference': missing_quest1 - missing_quest2\n",
    "})\n",
    "# Add percentage columns for better context\n",
    "missing_comparison['Quest_1_%'] = (missing_quest1 / len(quest_1) * 100).round(2)\n",
    "missing_comparison['Quest_2_%'] = (missing_quest2 / len(quest_2) * 100).round(2)\n",
    "\n",
    "print(missing_comparison)\n",
    "\n",
    "# Summary of total missing values\n",
    "print(f\"\\nTotal missing values - Quest 1: {missing_quest1.sum():,}\")\n",
    "print(f\"Total missing values - Quest 2: {missing_quest2.sum():,}\")\n",
    "\n",
    "# Check for columns with differing missing value counts\n",
    "differing_missing = missing_comparison[missing_comparison['Difference'] != 0]\n",
    "if not differing_missing.empty:\n",
    "    print(f\"\\nColumns with differing missing value counts ({len(differing_missing)}):\")\n",
    "    print(differing_missing)    \n",
    "else:\n",
    "    print(\"\\nMissing value counts match for all columns!\")\n",
    "print()\n",
    "\n",
    "# Unique values comparison  \n",
    "print(\"=\" * 60)\n",
    "print(\"UNIQUE VALUES COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "unique_quest1 = quest_1.nunique()\n",
    "unique_quest2 = quest_2.nunique()\n",
    "unique_comparison = pd.DataFrame({\n",
    "    'Quest_1_unique': unique_quest1,\n",
    "    'Quest_2_unique': unique_quest2,\n",
    "    'Difference': unique_quest1 - unique_quest2\n",
    "})\n",
    "# Add percentage of total rows for context\n",
    "unique_comparison['Quest_1_%_unique'] = (unique_quest1 / len(quest_1) * 100).round(2)\n",
    "unique_comparison['Quest_2_%_unique'] = (unique_quest2 / len(quest_2) * 100).round(2)\n",
    "\n",
    "print(unique_comparison)\n",
    "\n",
    "# Check for columns with differing unique value counts  \n",
    "differing_unique = unique_comparison[unique_comparison['Difference'] != 0]\n",
    "if not differing_unique.empty:\n",
    "    print(f\"\\nColumns with differing unique value counts ({len(differing_unique)}):\")\n",
    "    print(differing_unique)\n",
    "else:\n",
    "    print(\"\\nUnique value counts match for all columns!\")\n",
    "\n",
    "# Identify potential categorical vs continuous columns\n",
    "categorical_threshold = 0.05  # Less than 5% unique values might be categorical\n",
    "print(f\"\\nPotential categorical columns (< {categorical_threshold*100}% unique values):\")\n",
    "for df_name, df in [('Quest_1', quest_1), ('Quest_2', quest_2)]:\n",
    "    categorical_cols = []\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() / len(df) < categorical_threshold and df[col].nunique() > 1:\n",
    "            categorical_cols.append(col)\n",
    "    print(f\"{df_name}: {categorical_cols}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2b000",
   "metadata": {},
   "source": [
    "## **3. Content-Level Comparison**\n",
    "\n",
    "This section performs deep comparison of actual data values and statistical properties:\n",
    "- **Row-level analysis**: Identify missing/extra rows between dataframes \n",
    "- **Exact matches**: Identify rows that are identical across both dataframes \n",
    "- **Value-level differences**: Find specific cells where values differ \n",
    "- **Summary statistics**: Compare means, medians, and standard deviations for numerical columns\n",
    "- **Data ranges**: Compare min/max values and identify outliers\n",
    "- **Duplicate records**: Check for and compare duplicate rows within each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-level analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"ROW-LEVEL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Only proceed if both dataframes have the same columns\n",
    "if list(quest_1.columns) == list(quest_2.columns):\n",
    "    print(f\"Quest 1 total rows: {len(quest_1):,}\")\n",
    "    print(f\"Quest 2 total rows: {len(quest_2):,}\")\n",
    "    \n",
    "    # Find rows only in Quest 1\n",
    "    quest_1_only = quest_1[~quest_1.isin(quest_2).all(axis=1)]\n",
    "    quest_1_only = quest_1_only.dropna(how='all')  # Remove empty rows from comparison\n",
    "    \n",
    "    # Find rows only in Quest 2  \n",
    "    quest_2_only = quest_2[~quest_2.isin(quest_1).all(axis=1)]\n",
    "    quest_2_only = quest_2_only.dropna(how='all')  # Remove empty rows from comparison\n",
    "    \n",
    "    print(f\"Rows only in Quest 1: {len(quest_1_only):,}\")\n",
    "    print(f\"Rows only in Quest 2: {len(quest_2_only):,}\")\n",
    "    \n",
    "    # Calculate overlap\n",
    "    total_unique_rows = len(quest_1_only) + len(quest_2_only)\n",
    "    total_rows = len(quest_1) + len(quest_2)\n",
    "    overlap_estimate = total_rows - total_unique_rows\n",
    "    print(f\"Estimated overlapping rows: {overlap_estimate:,}\")\n",
    "    \n",
    "    if len(quest_1_only) > 0:\n",
    "        print(f\"\\nSample rows only in Quest 1:\")\n",
    "        print(quest_1_only.head(3))\n",
    "        \n",
    "    if len(quest_2_only) > 0:\n",
    "        print(f\"\\nSample rows only in Quest 2:\")\n",
    "        print(quest_2_only.head(3))\n",
    "else:\n",
    "    print(\"Cannot perform row-level analysis - column structures differ between dataframes\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Exact matches analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"EXACT MATCHES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if list(quest_1.columns) == list(quest_2.columns):\n",
    "    # More accurate way to find exact matches\n",
    "    quest_1_str = quest_1.astype(str)\n",
    "    quest_2_str = quest_2.astype(str)\n",
    "    \n",
    "    # Create a combined key for each row to compare\n",
    "    quest_1_combined = quest_1_str.apply(lambda x: '|'.join(x), axis=1)\n",
    "    quest_2_combined = quest_2_str.apply(lambda x: '|'.join(x), axis=1)\n",
    "    \n",
    "    # Find exact matches\n",
    "    exact_matches = quest_1_combined.isin(quest_2_combined)\n",
    "    num_exact_matches = exact_matches.sum()\n",
    "    \n",
    "    print(f\"Total exact row matches: {num_exact_matches:,}\")\n",
    "    print(f\"Match rate: {(num_exact_matches / len(quest_1) * 100):.2f}%\")\n",
    "    \n",
    "    if num_exact_matches > 0 and num_exact_matches < len(quest_1):\n",
    "        print(f\"\\nSample exact matching rows (from Quest 1):\")\n",
    "        matching_rows = quest_1[exact_matches]\n",
    "        print(matching_rows.head(3))\n",
    "else:\n",
    "    print(\"Cannot perform exact match analysis - column structures differ\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Value-level differences (for common columns only)\n",
    "print(\"=\" * 60)\n",
    "print(\"VALUE-LEVEL DIFFERENCES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "common_columns = list(set(quest_1.columns) & set(quest_2.columns))\n",
    "print(f\"Analyzing {len(common_columns)} common columns\")\n",
    "\n",
    "if len(common_columns) > 0 and len(quest_1) == len(quest_2):\n",
    "    differences_summary = {}\n",
    "    \n",
    "    for col in common_columns:\n",
    "        # Compare values for this column\n",
    "        col_differences = (quest_1[col] != quest_2[col]).sum()\n",
    "        differences_summary[col] = col_differences\n",
    "    \n",
    "    differences_df = pd.DataFrame({\n",
    "        'Column': differences_summary.keys(),\n",
    "        'Different_Values': differences_summary.values(),\n",
    "        'Difference_Rate_%': [(v/len(quest_1)*100) for v in differences_summary.values()]\n",
    "    })\n",
    "    \n",
    "    print(\"Value differences by column:\")\n",
    "    print(differences_df.round(2))\n",
    "    \n",
    "    # Show columns with highest differences\n",
    "    top_differences = differences_df.nlargest(5, 'Different_Values')\n",
    "    if not top_differences.empty and top_differences.iloc[0]['Different_Values'] > 0:\n",
    "        print(f\"\\nTop columns with most differences:\")\n",
    "        print(top_differences)\n",
    "else:\n",
    "    print(\"Cannot perform value-level comparison - different row counts or no common columns\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Summary statistics comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY STATISTICS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get numeric columns that exist in both dataframes\n",
    "numeric_cols_q1 = quest_1.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols_q2 = quest_2.select_dtypes(include=[np.number]).columns\n",
    "common_numeric_cols = list(set(numeric_cols_q1) & set(numeric_cols_q2))\n",
    "\n",
    "if len(common_numeric_cols) > 0:\n",
    "    print(f\"Comparing statistics for {len(common_numeric_cols)} common numeric columns\")\n",
    "    \n",
    "    stats_comparison = pd.DataFrame(index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'])\n",
    "    \n",
    "    for col in common_numeric_cols:\n",
    "        quest_1_stats = quest_1[col].describe()\n",
    "        quest_2_stats = quest_2[col].describe()\n",
    "        \n",
    "        stats_comparison[f'{col}_Quest1'] = quest_1_stats\n",
    "        stats_comparison[f'{col}_Quest2'] = quest_2_stats\n",
    "        stats_comparison[f'{col}_Diff'] = quest_1_stats - quest_2_stats\n",
    "    \n",
    "    print(stats_comparison.round(3))\n",
    "else:\n",
    "    print(\"No common numeric columns found for statistical comparison\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Data ranges comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA RANGES COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(common_numeric_cols) > 0:\n",
    "    ranges_comparison = []\n",
    "    \n",
    "    for col in common_numeric_cols:\n",
    "        q1_min, q1_max = quest_1[col].min(), quest_1[col].max()\n",
    "        q2_min, q2_max = quest_2[col].min(), quest_2[col].max()\n",
    "        \n",
    "        ranges_comparison.append({\n",
    "            'Column': col,\n",
    "            'Quest1_Min': q1_min,\n",
    "            'Quest1_Max': q1_max,\n",
    "            'Quest1_Range': q1_max - q1_min,\n",
    "            'Quest2_Min': q2_min,\n",
    "            'Quest2_Max': q2_max,\n",
    "            'Quest2_Range': q2_max - q2_min,\n",
    "            'Range_Diff': (q1_max - q1_min) - (q2_max - q2_min)\n",
    "        })\n",
    "    \n",
    "    ranges_df = pd.DataFrame(ranges_comparison)\n",
    "    print(ranges_df.round(3))\n",
    "    \n",
    "    # Identify columns with significant range differences\n",
    "    significant_range_diff = ranges_df[abs(ranges_df['Range_Diff']) > 0.01]\n",
    "    if not significant_range_diff.empty:\n",
    "        print(f\"\\nColumns with notable range differences:\")\n",
    "        print(significant_range_diff[['Column', 'Quest1_Range', 'Quest2_Range', 'Range_Diff']].round(3))\n",
    "else:\n",
    "    print(\"No numeric columns available for range comparison\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Duplicate records check\n",
    "print(\"=\" * 60)\n",
    "print(\"DUPLICATE RECORDS CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "duplicates_q1 = quest_1.duplicated()\n",
    "duplicates_q2 = quest_2.duplicated()\n",
    "\n",
    "print(f\"Quest 1 - Total rows: {len(quest_1):,}\")\n",
    "print(f\"Quest 1 - Duplicate rows: {duplicates_q1.sum():,} ({duplicates_q1.sum()/len(quest_1)*100:.2f}%)\")\n",
    "print(f\"Quest 2 - Total rows: {len(quest_2):,}\")\n",
    "print(f\"Quest 2 - Duplicate rows: {duplicates_q2.sum():,} ({duplicates_q2.sum()/len(quest_2)*100:.2f}%)\")\n",
    "\n",
    "if duplicates_q1.sum() > 0:\n",
    "    print(f\"\\nSample duplicate rows from Quest 1:\")\n",
    "    print(quest_1[duplicates_q1].head(3))\n",
    "\n",
    "if duplicates_q2.sum() > 0:\n",
    "    print(f\"\\nSample duplicate rows from Quest 2:\")\n",
    "    print(quest_2[duplicates_q2].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bfb25",
   "metadata": {},
   "source": [
    "## **4. Tolerance-Based Comparison**\n",
    "\n",
    "This section performs numerical comparisons with tolerance levels for more realistic data validation:\n",
    "- **Floating-point precision**: Use tolerance levels for numerical comparisons\n",
    "- **Percentage differences**: Calculate relative differences for numerical columns  \n",
    "- **Statistical significance**: Identify meaningful vs trivial differences\n",
    "- **Threshold-based matching**: Define acceptable variance levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affacd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance-based numerical comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"TOLERANCE-BASED NUMERICAL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define tolerance levels\n",
    "absolute_tolerance = 0.001  # For values close to zero\n",
    "relative_tolerance = 0.01   # 1% relative difference\n",
    "\n",
    "if len(common_numeric_cols) > 0 and len(quest_1) == len(quest_2):\n",
    "    tolerance_results = []\n",
    "    \n",
    "    for col in common_numeric_cols:\n",
    "        # Calculate absolute differences\n",
    "        abs_diff = abs(quest_1[col] - quest_2[col])\n",
    "        \n",
    "        # Calculate relative differences (avoid division by zero)\n",
    "        quest_1_vals = quest_1[col].replace(0, np.nan)\n",
    "        rel_diff = abs((quest_1[col] - quest_2[col]) / quest_1_vals).fillna(0)\n",
    "        \n",
    "        # Apply tolerance checks\n",
    "        within_abs_tolerance = abs_diff <= absolute_tolerance\n",
    "        within_rel_tolerance = rel_diff <= relative_tolerance\n",
    "        \n",
    "        # Combined tolerance check\n",
    "        within_tolerance = within_abs_tolerance | within_rel_tolerance\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_comparisons = len(quest_1)\n",
    "        within_tolerance_count = within_tolerance.sum()\n",
    "        tolerance_rate = (within_tolerance_count / total_comparisons) * 100\n",
    "        \n",
    "        # Statistical measures\n",
    "        mean_abs_diff = abs_diff.mean()\n",
    "        max_abs_diff = abs_diff.max()\n",
    "        mean_rel_diff = rel_diff.mean() * 100  # Convert to percentage\n",
    "        \n",
    "        tolerance_results.append({\n",
    "            'Column': col,\n",
    "            'Within_Tolerance_Count': within_tolerance_count,\n",
    "            'Total_Comparisons': total_comparisons,\n",
    "            'Tolerance_Rate_%': tolerance_rate,\n",
    "            'Mean_Abs_Diff': mean_abs_diff,\n",
    "            'Max_Abs_Diff': max_abs_diff,\n",
    "            'Mean_Rel_Diff_%': mean_rel_diff\n",
    "        })\n",
    "    \n",
    "    tolerance_df = pd.DataFrame(tolerance_results)\n",
    "    print(f\"Tolerance Analysis (Absolute: {absolute_tolerance}, Relative: {relative_tolerance*100}%)\")\n",
    "    print(tolerance_df.round(3))\n",
    "    \n",
    "    # Identify columns with poor tolerance rates\n",
    "    poor_tolerance = tolerance_df[tolerance_df['Tolerance_Rate_%'] < 95]\n",
    "    if not poor_tolerance.empty:\n",
    "        print(f\"\\nColumns with < 95% tolerance rate (may need investigation):\")\n",
    "        print(poor_tolerance[['Column', 'Tolerance_Rate_%', 'Mean_Abs_Diff', 'Mean_Rel_Diff_%']].round(3))\n",
    "    else:\n",
    "        print(\"\\nAll columns meet the 95% tolerance threshold!\")\n",
    "\n",
    "else:\n",
    "    print(\"Cannot perform tolerance-based comparison - incompatible dataframes\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Statistical significance testing (for numerical columns)\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(common_numeric_cols) > 0:\n",
    "    from scipy import stats\n",
    "    \n",
    "    significance_results = []\n",
    "    \n",
    "    for col in common_numeric_cols:\n",
    "        # Remove NaN values for statistical tests\n",
    "        quest_1_clean = quest_1[col].dropna()\n",
    "        quest_2_clean = quest_2[col].dropna()\n",
    "        \n",
    "        if len(quest_1_clean) > 1 and len(quest_2_clean) > 1:\n",
    "            # Perform t-test\n",
    "            t_stat, p_value = stats.ttest_ind(quest_1_clean, quest_2_clean)\n",
    "            \n",
    "            # Effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt(((len(quest_1_clean) - 1) * quest_1_clean.var() + \n",
    "                                 (len(quest_2_clean) - 1) * quest_2_clean.var()) / \n",
    "                                (len(quest_1_clean) + len(quest_2_clean) - 2))\n",
    "            \n",
    "            if pooled_std != 0:\n",
    "                cohens_d = (quest_1_clean.mean() - quest_2_clean.mean()) / pooled_std\n",
    "            else:\n",
    "                cohens_d = 0\n",
    "                \n",
    "            # Interpret results\n",
    "            is_significant = p_value < 0.05\n",
    "            effect_size_interpretation = \"Small\" if abs(cohens_d) < 0.5 else \"Medium\" if abs(cohens_d) < 0.8 else \"Large\"\n",
    "            \n",
    "            significance_results.append({\n",
    "                'Column': col,\n",
    "                'T_Statistic': t_stat,\n",
    "                'P_Value': p_value,\n",
    "                'Significant_5%': is_significant,\n",
    "                'Cohens_D': cohens_d,\n",
    "                'Effect_Size': effect_size_interpretation,\n",
    "                'Quest1_Mean': quest_1_clean.mean(),\n",
    "                'Quest2_Mean': quest_2_clean.mean()\n",
    "            })\n",
    "    \n",
    "    if significance_results:\n",
    "        significance_df = pd.DataFrame(significance_results)\n",
    "        print(\"Statistical Significance Testing (t-test):\")\n",
    "        print(significance_df.round(4))\n",
    "        \n",
    "        significant_cols = significance_df[significance_df['Significant_5%'] == True]\n",
    "        if not significant_cols.empty:\n",
    "            print(f\"\\nStatistically significant differences found in {len(significant_cols)} columns:\")\n",
    "            print(significant_cols[['Column', 'P_Value', 'Effect_Size', 'Quest1_Mean', 'Quest2_Mean']].round(4))\n",
    "        else:\n",
    "            print(\"\\nNo statistically significant differences found!\")\n",
    "    else:\n",
    "        print(\"Unable to perform statistical tests - insufficient data\")\n",
    "else:\n",
    "    print(\"No numeric columns available for statistical testing\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8111b7e",
   "metadata": {},
   "source": [
    "## **5. Visualization & Reporting**\n",
    "\n",
    "This section creates visual representations and comprehensive reports of the comparison results:\n",
    "- **Difference heatmaps**: Visual representation of where differences occur\n",
    "- **Distribution plots**: Compare data distributions between dataframes  \n",
    "- **Summary reports**: Comprehensive comparison summary\n",
    "- **Quality metrics**: Overall data comparison scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VISUALIZATION & REPORTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Difference Heatmap (for numerical columns with same dimensions)\n",
    "if len(common_numeric_cols) > 0 and len(quest_1) == len(quest_2) and len(quest_1) < 1000:  # Limit size for visualization\n",
    "    print(\"Creating difference heatmap...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Dataframe Comparison Heatmaps', fontsize=16)\n",
    "    \n",
    "    # Create difference matrix for numeric columns only\n",
    "    numeric_quest1 = quest_1[common_numeric_cols].fillna(0)\n",
    "    numeric_quest2 = quest_2[common_numeric_cols].fillna(0)\n",
    "    difference_matrix = numeric_quest1 - numeric_quest2\n",
    "    \n",
    "    # Heatmap 1: Absolute differences\n",
    "    sns.heatmap(difference_matrix.head(50).T, cmap='RdBu_r', center=0, \n",
    "                ax=axes[0,0], cbar_kws={'label': 'Difference'})\n",
    "    axes[0,0].set_title('Absolute Differences (First 50 rows)')\n",
    "    axes[0,0].set_xlabel('Row Index')\n",
    "    axes[0,0].set_ylabel('Columns')\n",
    "    \n",
    "    # Heatmap 2: Missing values pattern\n",
    "    missing_pattern_q1 = quest_1[common_numeric_cols].isnull().astype(int)\n",
    "    missing_pattern_q2 = quest_2[common_numeric_cols].isnull().astype(int)\n",
    "    missing_diff = missing_pattern_q1 - missing_pattern_q2\n",
    "    \n",
    "    sns.heatmap(missing_diff.head(50).T, cmap='RdYlBu', center=0,\n",
    "                ax=axes[0,1], cbar_kws={'label': 'Missing Pattern Diff'})\n",
    "    axes[0,1].set_title('Missing Value Pattern Differences')\n",
    "    axes[0,1].set_xlabel('Row Index')\n",
    "    axes[0,1].set_ylabel('Columns')\n",
    "    \n",
    "    # Heatmap 3: Correlation matrix comparison\n",
    "    if len(common_numeric_cols) > 1:\n",
    "        corr_q1 = quest_1[common_numeric_cols].corr()\n",
    "        corr_q2 = quest_2[common_numeric_cols].corr()\n",
    "        corr_diff = corr_q1 - corr_q2\n",
    "        \n",
    "        sns.heatmap(corr_diff, annot=True, cmap='RdBu_r', center=0, fmt='.2f',\n",
    "                    ax=axes[1,0], cbar_kws={'label': 'Correlation Difference'})\n",
    "        axes[1,0].set_title('Correlation Matrix Differences')\n",
    "    \n",
    "    # Heatmap 4: Summary statistics heatmap\n",
    "    if len(common_numeric_cols) > 0:\n",
    "        summary_data = []\n",
    "        for col in common_numeric_cols[:10]:  # Limit to first 10 columns\n",
    "            q1_stats = quest_1[col].describe()\n",
    "            q2_stats = quest_2[col].describe()\n",
    "            diff_stats = q1_stats - q2_stats\n",
    "            summary_data.append(diff_stats[['mean', 'std', 'min', 'max']])\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data, index=common_numeric_cols[:10])\n",
    "            sns.heatmap(summary_df, annot=True, cmap='RdBu_r', center=0, fmt='.2f',\n",
    "                        ax=axes[1,1], cbar_kws={'label': 'Statistics Difference'})\n",
    "            axes[1,1].set_title('Summary Statistics Differences')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping heatmap - datasets too large or incompatible structures\")\n",
    "\n",
    "# 2. Distribution Comparison Plots\n",
    "if len(common_numeric_cols) > 0:\n",
    "    print(\"\\nCreating distribution comparison plots...\")\n",
    "    \n",
    "    # Select up to 4 columns for distribution plots\n",
    "    plot_columns = common_numeric_cols[:4]\n",
    "    \n",
    "    if len(plot_columns) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('Distribution Comparisons', fontsize=16)\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, col in enumerate(plot_columns):\n",
    "            if i < 4:\n",
    "                # Histogram comparison\n",
    "                axes[i].hist(quest_1[col].dropna(), alpha=0.7, label='Quest 1', bins=30, color='blue')\n",
    "                axes[i].hist(quest_2[col].dropna(), alpha=0.7, label='Quest 2', bins=30, color='red')\n",
    "                axes[i].set_title(f'Distribution: {col}')\n",
    "                axes[i].set_xlabel('Value')\n",
    "                axes[i].set_ylabel('Frequency')\n",
    "                axes[i].legend()\n",
    "                axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide empty subplots\n",
    "        for i in range(len(plot_columns), 4):\n",
    "            axes[i].set_visible(False)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 3. Comprehensive Summary Report\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPREHENSIVE COMPARISON SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "report_data = {\n",
    "    'Comparison_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Quest_1_Shape': f\"{quest_1.shape[0]} rows √ó {quest_1.shape[1]} columns\",\n",
    "    'Quest_2_Shape': f\"{quest_2.shape[0]} rows √ó {quest_2.shape[1]} columns\",\n",
    "    'Shape_Match': quest_1.shape == quest_2.shape,\n",
    "    'Column_Match': list(quest_1.columns) == list(quest_2.columns),\n",
    "    'Common_Columns': len(common_columns),\n",
    "    'Common_Numeric_Columns': len(common_numeric_cols) if 'common_numeric_cols' in locals() else 0,\n",
    "    'Quest_1_Total_Missing': quest_1.isnull().sum().sum(),\n",
    "    'Quest_2_Total_Missing': quest_2.isnull().sum().sum(),\n",
    "    'Quest_1_Duplicates': quest_1.duplicated().sum(),\n",
    "    'Quest_2_Duplicates': quest_2.duplicated().sum()\n",
    "}\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(list(report_data.items()), columns=['Metric', 'Value'])\n",
    "print(\"EXECUTIVE SUMMARY:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# 4. Quality Scorecard\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY SCORECARD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scorecard = {}\n",
    "\n",
    "# Structure Score (0-100)\n",
    "structure_score = 0\n",
    "if quest_1.shape == quest_2.shape:\n",
    "    structure_score += 40\n",
    "if list(quest_1.columns) == list(quest_2.columns):\n",
    "    structure_score += 30\n",
    "if quest_1.dtypes.equals(quest_2.dtypes):\n",
    "    structure_score += 30\n",
    "\n",
    "# Data Quality Score (0-100) \n",
    "quality_score = 0\n",
    "total_cells_q1 = quest_1.shape[0] * quest_1.shape[1]\n",
    "total_cells_q2 = quest_2.shape[0] * quest_2.shape[1]\n",
    "\n",
    "if total_cells_q1 > 0 and total_cells_q2 > 0:\n",
    "    missing_rate_q1 = (quest_1.isnull().sum().sum() / total_cells_q1) * 100\n",
    "    missing_rate_q2 = (quest_2.isnull().sum().sum() / total_cells_q2) * 100\n",
    "    \n",
    "    # Score based on missing data (lower missing = higher score)\n",
    "    avg_missing_rate = (missing_rate_q1 + missing_rate_q2) / 2\n",
    "    quality_score = max(0, 100 - avg_missing_rate * 2)  # Penalty for missing data\n",
    "\n",
    "# Overall Score\n",
    "overall_score = (structure_score + quality_score) / 2\n",
    "\n",
    "scorecard_df = pd.DataFrame({\n",
    "    'Score_Category': ['Structure_Match', 'Data_Quality', 'Overall_Score'],\n",
    "    'Score': [structure_score, quality_score, overall_score],\n",
    "    'Grade': [\n",
    "        'A' if structure_score >= 90 else 'B' if structure_score >= 80 else 'C' if structure_score >= 70 else 'D' if structure_score >= 60 else 'F',\n",
    "        'A' if quality_score >= 90 else 'B' if quality_score >= 80 else 'C' if quality_score >= 70 else 'D' if quality_score >= 60 else 'F',\n",
    "        'A' if overall_score >= 90 else 'B' if overall_score >= 80 else 'C' if overall_score >= 70 else 'D' if overall_score >= 60 else 'F'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"QUALITY SCORECARD:\")\n",
    "print(scorecard_df.round(2).to_string(index=False))\n",
    "\n",
    "# 5. Recommendations\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "if quest_1.shape != quest_2.shape:\n",
    "    recommendations.append(\"‚ö†Ô∏è  CRITICAL: Dataframes have different shapes - investigate row/column differences\")\n",
    "\n",
    "if list(quest_1.columns) != list(quest_2.columns):\n",
    "    recommendations.append(\"‚ö†Ô∏è  WARNING: Column names differ - verify data mapping\")\n",
    "\n",
    "if quest_1.isnull().sum().sum() != quest_2.isnull().sum().sum():\n",
    "    recommendations.append(\"‚ÑπÔ∏è  INFO: Different missing value patterns detected\")\n",
    "\n",
    "if quest_1.duplicated().sum() > 0 or quest_2.duplicated().sum() > 0:\n",
    "    recommendations.append(\"‚ÑπÔ∏è  INFO: Duplicate records found - consider deduplication\")\n",
    "\n",
    "if overall_score < 80:\n",
    "    recommendations.append(\"üîç ACTION: Low overall score - detailed investigation recommended\")\n",
    "\n",
    "if len(recommendations) == 0:\n",
    "    recommendations.append(\"‚úÖ GOOD: No major issues detected in comparison\")\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1677a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
